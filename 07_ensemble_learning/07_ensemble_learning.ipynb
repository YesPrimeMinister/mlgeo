{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# Machine Learning in Geosciences ] \n",
    "Department of Applied Geoinformatics and Carthography, Charles University\n",
    "\n",
    "Lukas Brodsky lukas.brodsky@natur.cuni.cz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook covers these topics of the ensemble learning: \n",
    "\n",
    "* Comparison of hard and soft voting classifiers\n",
    "\n",
    "* Bagging ensembles\n",
    "\n",
    "* Feature importance example \n",
    "\n",
    "* Stacking ensemble \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "\n",
    "def image_path(fig_id):\n",
    "    return os.path.join(PROJECT_ROOT_DIR, \"images\", fig_id)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(image_path(fig_id) + \".png\", format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use generated data set\n",
    "\n",
    "# make_moons generate 2d binary classification datasets that are challenging to certain algorithms \n",
    "# including optional Gaussian noise.\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 2)\n",
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5272175581735962"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2580498754382393"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare hard and soft voting classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# hyperparameters (solver, n_estimators, gamma) \n",
    "log_clf = LogisticRegression(solver=\"liblinear\", random_state=42)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "svm_clf = SVC(gamma=\"auto\", random_state=42)\n",
    "\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(random_state=42,\n",
       "                                                 solver='liblinear')),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(n_estimators=10,\n",
       "                                                     random_state=42)),\n",
       "                             ('svc', SVC(gamma='auto', random_state=42))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression :  0.864\n",
      "RandomForestClassifier :  0.872\n",
      "SVC :  0.888\n",
      "VotingClassifier :  0.896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__,': ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(random_state=42,\n",
       "                                                 solver='liblinear')),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(n_estimators=10,\n",
       "                                                     random_state=42)),\n",
       "                             ('svc',\n",
       "                              SVC(gamma='auto', probability=True,\n",
       "                                  random_state=42))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf = LogisticRegression(solver=\"liblinear\", random_state=42)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "svm_clf = SVC(gamma=\"auto\", probability=True, random_state=42)\n",
    "\n",
    "# voting=soft\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='soft')\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression :  0.864\n",
      "RandomForestClassifier :  0.872\n",
      "SVC :  0.888\n",
      "VotingClassifier :  0.912\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__,': ',  accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging Decision Trees classifier (Bootstrap Aggregation) \n",
    "# estimators 500\n",
    "# max. samples 100 \n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(random_state=42), n_estimators=500,\n",
    "    max_samples=100, bootstrap=True, n_jobs=-1, random_state=42)\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.904\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.856\n"
     ]
    }
   ],
   "source": [
    "# Single Tree classifier\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "y_pred_tree = tree_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests from DecisionTree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(splitter=\"random\", max_leaf_nodes=16, random_state=42),\n",
    "    n_estimators=500, max_samples=1.0, bootstrap=True, n_jobs=-1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1, random_state=42)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare RF/DT results\n",
    "np.sum(y_pred == y_pred_rf) / len(y_pred) * 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-Bag evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8986666666666666\n"
     ]
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(random_state=42), n_estimators=500,\n",
    "    bootstrap=True, n_jobs=-1, oob_score=True, random_state=40)\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "\n",
    "print(bag_clf.oob_score_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag_clf.oob_decision_function_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance\n",
    "with MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import MNIST data set \n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "mnist.target = mnist.target.astype(np.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=10, random_state=42)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "rnd_clf.fit(mnist[\"data\"], mnist[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digit(data):\n",
    "    image = data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap = mpl.cm.gray, interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_digit(rnd_clf.feature_importances_)\n",
    "\n",
    "cbar = plt.colorbar(ticks=[rnd_clf.feature_importances_.min(), rnd_clf.feature_importances_.max()])\n",
    "cbar.ax.set_yticklabels(['Not important', 'Important'])\n",
    "\n",
    "# save_fig(\"mnist_feature_importance_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier Exercize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split MNIST data into a training set, a validation set, and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    mnist.data, mnist.target, test_size=10000, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=10000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train various classifiers: Random Forest classifier, Extra-Trees classifier, SVM and Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use n_estimators=10 \n",
    "# random_state=42\n",
    "\n",
    "random_forest_clf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "extra_trees_clf = ExtraTreesClassifier(n_estimators=10, random_state=42)\n",
    "svm_clf = LinearSVC(random_state=42, verbose=1, max_iter=500) # may be a non-linear as well \n",
    "mlp_clf = MLPClassifier(random_state=42, verbose=1)         # default parameters hidden_layer_sizes=100 / 50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(n_estimators=10, random_state=42)\n",
      "ExtraTreesClassifier(n_estimators=10, random_state=42)\n",
      "LinearSVC(random_state=42, verbose=1)\n",
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# fit the models: takes while! \n",
    "\n",
    "# estimators = [random_forest_clf, extra_trees_clf, svm_clf , mlp_clf]\n",
    "estimators = [random_forest_clf, extra_trees_clf, svm_clf]\n",
    "# estimators = [svm_clf]\n",
    "\n",
    "# train the estimatiors \n",
    "# TODO: parallelize (joblib) \n",
    "for estimator in estimators: \n",
    "    print(estimator)\n",
    "    estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9469, 0.9492, 0.8695]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the estimators score \n",
    "\n",
    "[estimator.score(X_val, y_val) for estimator in estimators]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.9469, 0.9492, 0.8695, 0.9663]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine them into an ensemble using a soft and hard voting classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_estimators = [\n",
    "    ('random_forest_clf', random_forest_clf), \n",
    "    ('extra_trees_clf', extra_trees_clf), \n",
    "    ('svm_clf', svm_clf), \n",
    "    ('mlp_clf', mlp_clf)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_jobs=-1\n",
    "\n",
    "voting_clf = VotingClassifier(named_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('random_forest_clf',\n",
       "                              RandomForestClassifier(n_estimators=10,\n",
       "                                                     random_state=42)),\n",
       "                             ('extra_trees_clf',\n",
       "                              ExtraTreesClassifier(n_estimators=10,\n",
       "                                                   random_state=42)),\n",
       "                             ('svm_clf', LinearSVC(random_state=42)),\n",
       "                             ('mlp_clf', MLPClassifier(random_state=42))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the voting classifier on X_train, y_train \n",
    "# takes while \n",
    "\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9626"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the voting score using the X_val, y_val\n",
    "voting_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the scores of the individual estimator? \n",
    "# voting_clf.estimators_ .. attribute to access any fitted sub-estimators by name.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove SVM. Does it help to improve performance? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('random_forest_clf',\n",
       "                              RandomForestClassifier(n_estimators=10,\n",
       "                                                     random_state=42)),\n",
       "                             ('extra_trees_clf',\n",
       "                              ExtraTreesClassifier(n_estimators=10,\n",
       "                                                   random_state=42)),\n",
       "                             ('svm_clf', None),\n",
       "                             ('mlp_clf', MLPClassifier(random_state=42))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the clf to None \n",
    "voting_clf.set_params(svm_clf=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the list of estimators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('random_forest_clf',\n",
       "  RandomForestClassifier(n_estimators=10, random_state=42)),\n",
       " ('extra_trees_clf', ExtraTreesClassifier(n_estimators=10, random_state=42)),\n",
       " ('svm_clf', None),\n",
       " ('mlp_clf', MLPClassifier(random_state=42))]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check \n",
    "voting_clf.estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RandomForestClassifier(n_estimators=10, random_state=42),\n",
       " ExtraTreesClassifier(n_estimators=10, random_state=42),\n",
       " MLPClassifier(random_state=42)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the estimator \n",
    "del voting_clf.estimators_[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's evaluate the `VotingClassifier` again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate VotingClassifier again\n",
    "voting_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bit better? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try using a soft voting classifier. Do not  retrain the classifier, just set `voting` to `\"soft\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf.voting = 'soft' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9715"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the score of the soft classifier! \n",
    "voting_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improvement? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it on the test set. How much better does it perform compared to the individual classifiers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9693"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.score(X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9437, 0.9474, 0.9636]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[estimator.score(X_test, y_test) for estimator in voting_clf.estimators_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Did the voting classifier reduce the error rate?\n",
    "# Compare it to the best model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: _Run the individual classifiers from the previous exercise to make predictions on the validation set, and create a new training set with the resulting predictions: each training instance is a vector containing the set of predictions from all your classifiers for an image, and the target is the image's class. Train a classifier on this new training set._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_predictions = np.empty((len(X_val), len(estimators)), dtype=np.float32)\n",
    "\n",
    "for index, estimator in enumerate(estimators):\n",
    "    X_val_predictions[:, index] = estimator.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 5., 5.],\n",
       "       [8., 8., 8.],\n",
       "       [2., 2., 2.],\n",
       "       ...,\n",
       "       [7., 7., 7.],\n",
       "       [6., 6., 6.],\n",
       "       [7., 7., 7.]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200, oob_score=True, random_state=42)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_forest_blender = RandomForestClassifier(n_estimators=200, oob_score=True, random_state=42)\n",
    "rnd_forest_blender.fit(X_val_predictions, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.951"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_forest_blender.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can fine-tune this blender or try other types of blenders, then select the best one using cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: the blender together with the classifiers form a stacking ensemble! \n",
    "\n",
    "Let's evaluate the ensemble on the test set. For each image in the test set, make predictions with all your classifiers, then feed the predictions to the blender to get the ensemble's predictions. \n",
    "\n",
    "How does it compare to the voting classifier you trained earlier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_predictions = np.empty((len(X_test), len(estimators)), dtype=np.float32)\n",
    "\n",
    "for index, estimator in enumerate(estimators):\n",
    "    X_test_predictions[:, index] = estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rnd_forest_blender.predict(X_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9505"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How good is the stacking ensemble compare to the soft voting classifier? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "nav_menu": {
   "height": "252px",
   "width": "333px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

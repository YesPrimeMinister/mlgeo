{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ___\n",
    "\n",
    "# [ Machine Learning in Geosciences ]\n",
    "\n",
    "**Department of Applied Geoinformatics and Carthography, Charles University** \n",
    "\n",
    "*Lukas Brodsky lukas.brodsky@natur.cuni.cz*\n",
    "\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn (first steps)\n",
    "\n",
    "Scikit-learn is a **Machine Learning Library for Python**. Scikit-learn is: \n",
    "* Simple and efficient tools for predictive data analysis\n",
    "* Accessible to everybody, and reusable in various contexts\n",
    "* Built on NumPy, SciPy, and matplotlib\n",
    "* Open source, commercially usable - BSD license\n",
    "\n",
    "After completing this lab, you shall know:\n",
    "\n",
    "* How to import sklearn modules. \n",
    "* How to run simple predictive analysis (classification and regression) with Scikit-learn in Python.\n",
    "\n",
    "WITHOUT ANY AMBITION OF TUNING THE MODEL!!!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "    \n",
    "Please refer to **[Scikit-learn official documentation](https://scikit-learn.org/)**, and use the **[Scikit-learn API Reference](https://scikit-learn.org/stable/modules/classes.html)**\n",
    "\n",
    "Used version (shall be 0.24.1):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Scikit-learn for simple classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn API \n",
    "\n",
    "# data set splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "# coding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.neighbors import KNeighborsClassifier \n",
    "# from sklearn.svm import SVC \n",
    "\n",
    "# validation metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# visualization\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# sample data\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data science libraries\n",
    "\n",
    "# nd-addrays\n",
    "import numpy as np\n",
    "\n",
    "# dataframes\n",
    "import pandas as pd\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt \n",
    "# notebook solution\n",
    "%matplotlib inline \n",
    "# seaborn works on top of matplotlib\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load iris data from sklearn\n",
    "# iris = datasets.load_iris()\n",
    "\n",
    "# or from seaborn\n",
    "df = sns.load_dataset('iris') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view sample of the data set \n",
    "import matplotlib.image as mpimg\n",
    "img = 'iris-dataset.png'\n",
    "img = mpimg.imread('iris-dataset.png')\n",
    "plt.figure(figsize=(15, 10), dpi=80)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the data set\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the input data features  data type \n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dimensionality\n",
    "# iris.data.shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing data\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vizualizace atributu - pruzkumova analyza \n",
    "sns.pairplot(data=df, hue = 'species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare features X and labels y for machine learning modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = df['species']\n",
    "df1 = df.copy()\n",
    "df1 = df1.drop('species', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the attributes \n",
    "X = df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kodovani trid \n",
    "le = LabelEncoder()\n",
    "num_codes = le.fit_transform(reference) \n",
    "num_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codes\n",
    "spec_code  = pd.concat([df['species'], pd.DataFrame(num_codes)], axis=1)\n",
    "\n",
    "for col in spec_code:\n",
    "    print(spec_code[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = num_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data (randomely) \n",
    "# nahodne rozdeleni \n",
    "X_train, X_test, y_train, y_test = train_test_split(X , y, test_size = 0.7, random_state = 42)\n",
    "\n",
    "print(\"Trenovaci mnozina \", X_train.shape)\n",
    "print(\"Testovaci mnozina \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model instance and parameters\n",
    "my_tree = DecisionTreeClassifier(max_depth=3, min_samples_split=2, splitter='random', random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the model\n",
    "my_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree cross validation\n",
    "cv_strom = cross_validate(my_tree, X_train,y_train, cv=5, scoring='f1_macro', return_estimator=True)\n",
    "print('Average F1-skore: {:.3f} '.format(cv_strom['test_score'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy on the test data set \n",
    "print('Accuray F1-score on test set: {:.3f}'.format(\n",
    "    round(f1_score(y_test, my_tree.predict(X_test), average='macro'), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = my_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred) \n",
    "plt.figure(figsize=(7,7))\n",
    "sns.heatmap(data=cm,linewidths=.5, annot=True, square=True, cmap='Blues')\n",
    "plt.ylabel('Reference')\n",
    "plt.xlabel('Predicted class')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize tree\n",
    "plt.figure(figsize=(9, 6), dpi=80)\n",
    "rozhodovaci_strom = plot_tree(decision_tree=my_tree, feature_names = df1.columns,\n",
    "class_names =[\"setosa\", \"vercicolor\", \"verginica\"] , filled=True ,  precision=2, rounded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Scikit-learn for simple regression\n",
    "\n",
    "(Support Vector Regression using linear and nonlinear kernels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn API\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate non-linear sample data \n",
    "X = np.sort(5 * np.random.rand(40, 1), axis=0)\n",
    "y = np.sin(X).ravel()\n",
    "\n",
    "# add some noise to the targets\n",
    "y[::5] += 2 * (0.5 - np.random.rand(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data dimensionality\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot them to see what we are going to work with \n",
    "plt.plot(X[:,0], y, 'k.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model instace \n",
    "svr_lin = SVR(kernel='linear', C=100, gamma='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the data to the model \n",
    "svr_lin.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the values given X \n",
    "lin_pred = svr_lin.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff = y - lin_pred\n",
    "# print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data points with your model results \n",
    "plt.plot(X[:,0], y, 'k.')\n",
    "plt.plot(X[:,0], lin_pred, 'b--')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test your non-linear model (polynomial)\n",
    "# degree 3 or other \n",
    "svr_poly = SVR(kernel='poly', C=100, gamma='auto', \n",
    "               degree=3, epsilon=.1, coef0=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the data to the model \n",
    "svr_poly.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions, given X \n",
    "poly_pred = svr_poly.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poly_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the input data and your model \n",
    "plt.plot(X[:,0], y, 'k.')\n",
    "plt.plot(X[:,0], poly_pred, 'b-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE \n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE lin vs. poly(3) \n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "print('RMSE linear     model: {}'.format(np.round(np.sqrt(mse(y, lin_pred)), 3)))\n",
    "print('RMSE polynomial model: {}'.format(np.round(np.sqrt(mse(y, poly_pred)), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So far all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
